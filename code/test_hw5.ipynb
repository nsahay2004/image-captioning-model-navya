{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: Image Captioning Tests\n",
    "---\n",
    "\n",
    "This is the Test Notebook that goes with **Homework 5: Image Captioning**! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *\n",
    "from decoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test RNN Decoder\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_size = 4\n",
    "window_size = 16\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "SOLUTION_SHAPE = (input_size, window_size, vocab_size)\n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "rnn_decoder = RNNDecoder(vocab_size, hidden_size, window_size)\n",
    "out = rnn_decoder(\n",
    "    tf.random.uniform([input_size, 64], minval=0, maxval=vocab_size),\n",
    "    tf.random.uniform([input_size, window_size], maxval=vocab_size)\n",
    ")\n",
    "epsilon = 1e-5\n",
    "assert out.shape == SOLUTION_SHAPE, \"Incorrect output shape\"\n",
    "assert not (tf.reduce_sum(out) > input_size * window_size - epsilon and tf.reduce_sum(out) < input_size * window_size + epsilon), \"Return logits, not probabilities\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Transformer Decoder\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_size = 4\n",
    "window_size = 16\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "SOLUTION_SHAPE = (input_size, window_size, vocab_size)\n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "transformer_decoder = TransformerDecoder(vocab_size, hidden_size, window_size)\n",
    "out = transformer_decoder(\n",
    "    tf.random.uniform([input_size, 64], minval=0, maxval=vocab_size),\n",
    "    tf.random.uniform([input_size, window_size], maxval=vocab_size)\n",
    ")\n",
    "epsilon = 1e-5\n",
    "assert out.shape == SOLUTION_SHAPE, \"Incorrect output shape\"\n",
    "assert not (tf.reduce_sum(out) > input_size * window_size - epsilon and tf.reduce_sum(out) < input_size * window_size + epsilon), \"Return logits, not probabilities\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "[[[ 0.08618154  0.06544782  0.03791777 -0.11725596  0.04927358\n",
      "   -0.04415976  0.04179837 -0.00203513]\n",
      "  [ 0.08619241  0.06545218  0.03793227 -0.11726703  0.0492707\n",
      "   -0.04415005  0.04181025 -0.00203775]\n",
      "  [ 0.08616404  0.06544071  0.03789285 -0.11723725  0.04927633\n",
      "   -0.04417628  0.04177818 -0.00202958]\n",
      "  [ 0.08619187  0.06545188  0.03792969 -0.11726543  0.0492686\n",
      "   -0.04415157  0.04180841 -0.00203603]]\n",
      "\n",
      " [[ 0.09340923  0.06543451  0.05652602 -0.12336385  0.04447593\n",
      "   -0.02758719  0.05595349 -0.00839301]\n",
      "  [ 0.0934089   0.06543487  0.05652836 -0.12336441  0.04447679\n",
      "   -0.02758227  0.05595471 -0.008393  ]\n",
      "  [ 0.09341807  0.06543844  0.05653481 -0.12337478  0.04448001\n",
      "   -0.02759013  0.05596163 -0.00839822]\n",
      "  [ 0.09342128  0.06544034  0.05654045 -0.12337963  0.04448243\n",
      "   -0.02758674  0.05596599 -0.00840028]]]\n",
      "Solution:\n",
      "[[[1.1887338  0.92231    1.1832824  1.4413241  0.9284028  1.2374643\n",
      "   1.2092555  1.6531762 ]\n",
      "  [1.1876637  0.920028   1.1839285  1.4362004  0.92912036 1.2364106\n",
      "   1.208142   1.6493324 ]\n",
      "  [1.1947478  0.92511594 1.18963    1.4394116  0.9363934  1.2449214\n",
      "   1.2101097  1.6523575 ]\n",
      "  [1.177351   0.9136951  1.1745526  1.4348177  0.91724336 1.2238563\n",
      "   1.2058568  1.6473322 ]]\n",
      "\n",
      " [[1.171719   0.91546506 1.2353648  1.2881929  0.955095   1.2792217\n",
      "   1.3040287  1.6174344 ]\n",
      "  [1.1937302  0.9304202  1.2462558  1.3073134  0.9750139  1.3008424\n",
      "   1.2973801  1.6244173 ]\n",
      "  [1.1734747  0.9167778  1.2366297  1.2896433  0.9566818  1.281148\n",
      "   1.304501   1.618589  ]\n",
      "  [1.204712   0.9370769  1.2490294  1.3173547  0.9849655  1.3102754\n",
      "   1.2873328  1.6238908 ]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Incorrect output values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 49\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SOLUTION\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(out, SOLUTION, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect output values",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(SOLUTION)\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTests passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect output values"
     ]
    }
   ],
   "source": [
    "# Test AttentionHead call function\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [[1.1887338,  0.92231,    1.1832824,  1.4413241,  0.9284028,  1.2374643,\n",
    "   1.2092555,  1.6531762, ],\n",
    "  [1.1876637,  0.920028,   1.1839285,  1.4362004,  0.92912036, 1.2364106,\n",
    "   1.208142,   1.6493324, ],\n",
    "  [1.1947478,  0.92511594, 1.18963,   1.4394116,  0.9363934,  1.2449214,\n",
    "   1.2101097,  1.6523575, ],\n",
    "  [1.177351,   0.9136951,  1.1745526,  1.4348177,  0.91724336, 1.2238563,\n",
    "   1.2058568,  1.6473322, ]],\n",
    "\n",
    " [[1.171719,   0.91546506, 1.2353648,  1.2881929,  0.955095,   1.2792217,\n",
    "   1.3040287,  1.6174344, ],\n",
    "  [1.1937302,  0.9304202,  1.2462558,  1.3073134,  0.9750139,  1.3008424,\n",
    "   1.2973801,  1.6244173, ],\n",
    "  [1.1734747,  0.9167778,  1.2366297,  1.2896433,  0.9566818,  1.281148,\n",
    "   1.304501,   1.618589,  ],\n",
    "  [1.204712,   0.9370769,  1.2490294,  1.3173547,  0.9849655,  1.3102754,\n",
    "   1.2873328,  1.6238908, ]]])\n",
    "\n",
    "def create_deterministic_attention_head(input_size, output_size, is_self_attention):\n",
    "    head = AttentionHead(input_size, output_size, is_self_attention)\n",
    "\n",
    "    head.K = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "    head.V = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "    head.Q = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "\n",
    "    return head\n",
    "\n",
    "input_size = 4\n",
    "batch_size = 2\n",
    "window_size_keys = 3\n",
    "window_size_values = 3\n",
    "window_size_queries = 4\n",
    "\n",
    "head = create_deterministic_attention_head(4, 8, False)\n",
    "\n",
    "out = head.call(\n",
    "    tf.random.uniform([batch_size, window_size_keys, input_size], dtype=np.float32),\n",
    "    tf.random.uniform([batch_size, window_size_values, input_size], dtype=np.float32),\n",
    "    tf.random.uniform([batch_size, window_size_queries, input_size], dtype=np.float32)\n",
    ").numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Incorrect output activation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 42\u001b[0m\n\u001b[1;32m     36\u001b[0m out \u001b[38;5;241m=\u001b[39m transformer_block(\n\u001b[1;32m     37\u001b[0m     tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform([batch_size, input_seq_length, embedding_size]),\n\u001b[1;32m     38\u001b[0m     tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform([batch_size, context_seq_length, embedding_size])\n\u001b[1;32m     39\u001b[0m )\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SOLUTION\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output activation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect output activation"
     ]
    }
   ],
   "source": [
    "# Test TransformerBlock\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [[0.         ,0.6974105  ,0.98577017 ,0.        ],\n",
    "  [0.         ,0.31697747 ,1.4552947  ,0.        ],\n",
    "  [0.         ,0.         ,1.6302229  ,0.        ],\n",
    "  [0.8908619  ,0.761421   ,0.         ,0.        ],\n",
    "  [0.         ,1.093846   ,0.         ,0.85964626],\n",
    "  [0.         ,0.         ,1.1071919  ,0.84442014],\n",
    "  [0.         ,0.7972666  ,0.         ,1.1266519 ],\n",
    "  [0.         ,0.         ,1.6696594  ,0.        ]],\n",
    "\n",
    " [[0.         ,0.         ,1.6952605  ,0.        ],\n",
    "  [0.         ,1.040991   ,0.9518903  ,0.        ],\n",
    "  [0.         ,0.9950613  ,0.19130549 ,0.47112876],\n",
    "  [0.         ,1.2255263  ,0.72682804 ,0.        ],\n",
    "  [0.59422725 ,0.         ,1.3293806  ,0.        ],\n",
    "  [1.56447    ,0.         ,0.         ,0.01488148],\n",
    "  [0.         ,0.6034657  ,0.         ,1.1571136 ],\n",
    "  [0.         ,0.18686305 ,0.29973274 ,1.1265295 ]]])\n",
    "\n",
    "batch_size = 2\n",
    "input_seq_length = 8\n",
    "embedding_size = 4\n",
    "context_seq_length = 6\n",
    "multiheadedattention = False\n",
    "\n",
    "transformer_block = TransformerBlock(embedding_size, multiheadedattention)\n",
    "transformer_block.self_atten = create_deterministic_attention_head(embedding_size, embedding_size, True)  # This is not correct. This is for testing purposes only\n",
    "transformer_block.self_context_atten = create_deterministic_attention_head(embedding_size, embedding_size, True)  # This is not correct. This is for testing purposes only\n",
    "transformer_block.ff_layer = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.constant()) #  # This is not correct. This is for testing purposes only\n",
    "\n",
    "out = transformer_block(\n",
    "    tf.random.uniform([batch_size, input_seq_length, embedding_size]),\n",
    "    tf.random.uniform([batch_size, context_seq_length, embedding_size])\n",
    ").numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "print(out)\n",
    "print(\"true\")\n",
    "print(SOLUTION)\n",
    "assert not (out < 0).any(), \"Incorrect output activation\"\n",
    "\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Positional Encoding\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
    "   1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
    " [ 8.4147096e-01,  9.9833414e-02,  9.9998331e-03,  9.9999981e-04,\n",
    "   5.4030228e-01,  9.9500418e-01,  9.9994999e-01,  9.9999952e-01],\n",
    " [ 9.0929741e-01,  1.9866933e-01,  1.9998666e-02,  1.9999987e-03,\n",
    "  -4.1614684e-01,  9.8006660e-01,  9.9980003e-01,  9.9999797e-01],\n",
    " [ 1.4112000e-01,  2.9552022e-01,  2.9995501e-02,  2.9999956e-03,\n",
    "  -9.8999250e-01,  9.5533651e-01,  9.9955004e-01,  9.9999553e-01]])\n",
    "\n",
    "input_size = 4\n",
    "window_size = 4\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "dummy_layer = tf.keras.layers.Dense(embed_size, kernel_initializer=tf.keras.initializers.constant())\n",
    "\n",
    "positional_encoding = PositionalEncoding(vocab_size, embed_size, window_size)\n",
    "positional_encoding.embedding = dummy_layer  # This is not correct. This is for testing purposes only\n",
    "\n",
    "out = positional_encoding.call(tf.random.uniform([input_size, window_size])).numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
