{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: Image Captioning Tests\n",
    "---\n",
    "\n",
    "This is the Test Notebook that goes with **Homework 5: Image Captioning**! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *\n",
    "from decoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test RNN Decoder\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_size = 4\n",
    "window_size = 16\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "SOLUTION_SHAPE = (input_size, window_size, vocab_size)\n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "rnn_decoder = RNNDecoder(vocab_size, hidden_size, window_size)\n",
    "out = rnn_decoder(\n",
    "    tf.random.uniform([input_size, 64], minval=0, maxval=vocab_size),\n",
    "    tf.random.uniform([input_size, window_size], maxval=vocab_size)\n",
    ")\n",
    "epsilon = 1e-5\n",
    "assert out.shape == SOLUTION_SHAPE, \"Incorrect output shape\"\n",
    "assert not (tf.reduce_sum(out) > input_size * window_size - epsilon and tf.reduce_sum(out) < input_size * window_size + epsilon), \"Return logits, not probabilities\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Transformer Decoder\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_size = 4\n",
    "window_size = 16\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "SOLUTION_SHAPE = (input_size, window_size, vocab_size)\n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "transformer_decoder = TransformerDecoder(vocab_size, hidden_size, window_size)\n",
    "out = transformer_decoder(\n",
    "    tf.random.uniform([input_size, 64], minval=0, maxval=vocab_size),\n",
    "    tf.random.uniform([input_size, window_size], maxval=vocab_size)\n",
    ")\n",
    "epsilon = 1e-5\n",
    "assert out.shape == SOLUTION_SHAPE, \"Incorrect output shape\"\n",
    "assert not (tf.reduce_sum(out) > input_size * window_size - epsilon and tf.reduce_sum(out) < input_size * window_size + epsilon), \"Return logits, not probabilities\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "[[[-0.18819048  0.01319544 -0.00533256 -0.43442103  0.8535673\n",
      "   -0.02970655  0.1656135  -0.49694026]\n",
      "  [-0.18476126  0.01145066 -0.00829701 -0.43083704  0.8496281\n",
      "   -0.03457779  0.16216531 -0.49654335]\n",
      "  [-0.1894315   0.01622316 -0.00643133 -0.43429783  0.84854674\n",
      "   -0.03001249  0.16360718 -0.49208438]\n",
      "  [-0.18801358  0.01454504 -0.00679014 -0.43338293  0.8494914\n",
      "   -0.03120077  0.16348056 -0.49391627]]\n",
      "\n",
      " [[-0.30495417  0.11300304  0.03921675 -0.50170153  0.8220751\n",
      "    0.10058844  0.23427151 -0.37989244]\n",
      "  [-0.3027879   0.11242488  0.03900083 -0.4994928   0.8185077\n",
      "    0.09900806  0.23182108 -0.37899724]\n",
      "  [-0.3039946   0.11294716  0.04098849 -0.5015391   0.82141984\n",
      "    0.10121913  0.23311988 -0.38040513]\n",
      "  [-0.2997103   0.11191354  0.04158559 -0.49761835  0.8148717\n",
      "    0.09882338  0.2282373  -0.37913343]]]\n",
      "Solution:\n",
      "[[[1.1887338  0.92231    1.1832824  1.4413241  0.9284028  1.2374643\n",
      "   1.2092555  1.6531762 ]\n",
      "  [1.1876637  0.920028   1.1839285  1.4362004  0.92912036 1.2364106\n",
      "   1.208142   1.6493324 ]\n",
      "  [1.1947478  0.92511594 1.18963    1.4394116  0.9363934  1.2449214\n",
      "   1.2101097  1.6523575 ]\n",
      "  [1.177351   0.9136951  1.1745526  1.4348177  0.91724336 1.2238563\n",
      "   1.2058568  1.6473322 ]]\n",
      "\n",
      " [[1.171719   0.91546506 1.2353648  1.2881929  0.955095   1.2792217\n",
      "   1.3040287  1.6174344 ]\n",
      "  [1.1937302  0.9304202  1.2462558  1.3073134  0.9750139  1.3008424\n",
      "   1.2973801  1.6244173 ]\n",
      "  [1.1734747  0.9167778  1.2366297  1.2896433  0.9566818  1.281148\n",
      "   1.304501   1.618589  ]\n",
      "  [1.204712   0.9370769  1.2490294  1.3173547  0.9849655  1.3102754\n",
      "   1.2873328  1.6238908 ]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Incorrect output values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 49\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SOLUTION\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(out, SOLUTION, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect output values",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(SOLUTION)\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTests passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect output values"
     ]
    }
   ],
   "source": [
    "# Test AttentionHead call function\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [[1.1887338,  0.92231,    1.1832824,  1.4413241,  0.9284028,  1.2374643,\n",
    "   1.2092555,  1.6531762, ],\n",
    "  [1.1876637,  0.920028,   1.1839285,  1.4362004,  0.92912036, 1.2364106,\n",
    "   1.208142,   1.6493324, ],\n",
    "  [1.1947478,  0.92511594, 1.18963,   1.4394116,  0.9363934,  1.2449214,\n",
    "   1.2101097,  1.6523575, ],\n",
    "  [1.177351,   0.9136951,  1.1745526,  1.4348177,  0.91724336, 1.2238563,\n",
    "   1.2058568,  1.6473322, ]],\n",
    "\n",
    " [[1.171719,   0.91546506, 1.2353648,  1.2881929,  0.955095,   1.2792217,\n",
    "   1.3040287,  1.6174344, ],\n",
    "  [1.1937302,  0.9304202,  1.2462558,  1.3073134,  0.9750139,  1.3008424,\n",
    "   1.2973801,  1.6244173, ],\n",
    "  [1.1734747,  0.9167778,  1.2366297,  1.2896433,  0.9566818,  1.281148,\n",
    "   1.304501,   1.618589,  ],\n",
    "  [1.204712,   0.9370769,  1.2490294,  1.3173547,  0.9849655,  1.3102754,\n",
    "   1.2873328,  1.6238908, ]]])\n",
    "\n",
    "def create_deterministic_attention_head(input_size, output_size, is_self_attention):\n",
    "    head = AttentionHead(input_size, output_size, is_self_attention)\n",
    "\n",
    "    head.K = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "    head.V = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "    head.Q = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "\n",
    "    return head\n",
    "\n",
    "input_size = 4\n",
    "batch_size = 2\n",
    "window_size_keys = 3\n",
    "window_size_values = 3\n",
    "window_size_queries = 4\n",
    "\n",
    "head = create_deterministic_attention_head(4, 8, False)\n",
    "\n",
    "out = head.call(\n",
    "    tf.random.uniform([batch_size, window_size_keys, input_size], dtype=np.float32),\n",
    "    tf.random.uniform([batch_size, window_size_values, input_size], dtype=np.float32),\n",
    "    tf.random.uniform([batch_size, window_size_queries, input_size], dtype=np.float32)\n",
    ").numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TransformerBlock\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [[0.         ,0.6974105  ,0.98577017 ,0.        ],\n",
    "  [0.         ,0.31697747 ,1.4552947  ,0.        ],\n",
    "  [0.         ,0.         ,1.6302229  ,0.        ],\n",
    "  [0.8908619  ,0.761421   ,0.         ,0.        ],\n",
    "  [0.         ,1.093846   ,0.         ,0.85964626],\n",
    "  [0.         ,0.         ,1.1071919  ,0.84442014],\n",
    "  [0.         ,0.7972666  ,0.         ,1.1266519 ],\n",
    "  [0.         ,0.         ,1.6696594  ,0.        ]],\n",
    "\n",
    " [[0.         ,0.         ,1.6952605  ,0.        ],\n",
    "  [0.         ,1.040991   ,0.9518903  ,0.        ],\n",
    "  [0.         ,0.9950613  ,0.19130549 ,0.47112876],\n",
    "  [0.         ,1.2255263  ,0.72682804 ,0.        ],\n",
    "  [0.59422725 ,0.         ,1.3293806  ,0.        ],\n",
    "  [1.56447    ,0.         ,0.         ,0.01488148],\n",
    "  [0.         ,0.6034657  ,0.         ,1.1571136 ],\n",
    "  [0.         ,0.18686305 ,0.29973274 ,1.1265295 ]]])\n",
    "\n",
    "batch_size = 2\n",
    "input_seq_length = 8\n",
    "embedding_size = 4\n",
    "context_seq_length = 6\n",
    "multiheadedattention = False\n",
    "\n",
    "transformer_block = TransformerBlock(embedding_size, multiheadedattention)\n",
    "transformer_block.self_atten = create_deterministic_attention_head(embedding_size, embedding_size, True)  # This is not correct. This is for testing purposes only\n",
    "transformer_block.self_context_atten = create_deterministic_attention_head(embedding_size, embedding_size, True)  # This is not correct. This is for testing purposes only\n",
    "transformer_block.ff_layer = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.constant()) #  # This is not correct. This is for testing purposes only\n",
    "\n",
    "out = transformer_block(\n",
    "    tf.random.uniform([batch_size, input_seq_length, embedding_size]),\n",
    "    tf.random.uniform([batch_size, context_seq_length, embedding_size])\n",
    ").numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "print(out)\n",
    "print(\"true\")\n",
    "print(SOLUTION)\n",
    "assert not (out < 0).any(), \"Incorrect output activation\"\n",
    "\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Positional Encoding\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
    "   1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
    " [ 8.4147096e-01,  9.9833414e-02,  9.9998331e-03,  9.9999981e-04,\n",
    "   5.4030228e-01,  9.9500418e-01,  9.9994999e-01,  9.9999952e-01],\n",
    " [ 9.0929741e-01,  1.9866933e-01,  1.9998666e-02,  1.9999987e-03,\n",
    "  -4.1614684e-01,  9.8006660e-01,  9.9980003e-01,  9.9999797e-01],\n",
    " [ 1.4112000e-01,  2.9552022e-01,  2.9995501e-02,  2.9999956e-03,\n",
    "  -9.8999250e-01,  9.5533651e-01,  9.9955004e-01,  9.9999553e-01]])\n",
    "\n",
    "input_size = 4\n",
    "window_size = 4\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "dummy_layer = tf.keras.layers.Dense(embed_size, kernel_initializer=tf.keras.initializers.constant())\n",
    "\n",
    "positional_encoding = PositionalEncoding(vocab_size, embed_size, window_size)\n",
    "positional_encoding.embedding = dummy_layer  # This is not correct. This is for testing purposes only\n",
    "\n",
    "out = positional_encoding.call(tf.random.uniform([input_size, window_size])).numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
