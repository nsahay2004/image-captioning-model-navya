{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: Image Captioning Tests\n",
    "---\n",
    "\n",
    "This is the Test Notebook that goes with **Homework 5: Image Captioning**! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *\n",
    "from decoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'rnn_decoder_1' (type RNNDecoder).\n\nLayer \"dense_6\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(4, 16, 32), dtype=float32, numpy=\narray([[[ 1.45733625e-01, -1.35873660e-01,  1.47979915e-01, ...,\n          3.55866104e-02, -1.86398923e-01, -2.29234964e-01],\n        [ 1.20293491e-01, -1.90315306e-01,  1.29939348e-01, ...,\n         -2.82574585e-03, -1.61929637e-01, -2.14414209e-01],\n        [ 1.00918509e-01, -1.69977397e-01,  1.04164697e-01, ...,\n         -2.50892974e-02, -1.46456361e-01, -1.70868263e-01],\n        ...,\n        [ 4.12754640e-02, -4.02896143e-02,  2.84471344e-02, ...,\n         -5.68455569e-02, -2.42954865e-02, -9.55829024e-03],\n        [ 3.98230366e-02, -4.01531495e-02,  2.96767913e-02, ...,\n         -5.71684316e-02, -2.24347804e-02, -9.09954589e-03],\n        [ 3.85242254e-02, -3.97739597e-02,  3.09780911e-02, ...,\n         -5.72667308e-02, -2.04258822e-02, -9.07866657e-03]],\n\n       [[ 1.01260148e-01, -1.47003919e-01,  8.32417831e-02, ...,\n          2.91540772e-02, -1.77253261e-01, -1.49628803e-01],\n        [ 9.48951766e-02, -1.65624052e-01,  5.37594520e-02, ...,\n         -1.18612265e-02, -1.25592828e-01, -1.81260929e-01],\n        [ 7.56906047e-02, -1.37855321e-01,  3.71033140e-02, ...,\n         -3.39518823e-02, -1.01178534e-01, -1.44572258e-01],\n        ...,\n        [ 3.33542340e-02, -4.23070975e-02,  3.52598056e-02, ...,\n         -6.15393706e-02, -1.57366358e-02, -1.84930544e-02],\n        [ 3.29130106e-02, -3.27946916e-02,  3.05698775e-02, ...,\n         -5.87866157e-02, -1.07600242e-02, -1.56205604e-02],\n        [ 3.32932547e-02, -2.52699815e-02,  2.62472034e-02, ...,\n         -5.71409427e-02, -8.29853769e-03, -1.36502124e-02]],\n\n       [[ 1.58701032e-01, -9.26301032e-02,  1.81446746e-01, ...,\n          2.02374905e-02, -1.28130287e-01, -1.02187917e-01],\n        [ 1.41461164e-01, -1.88737422e-01,  1.29423350e-01, ...,\n         -9.28472541e-03, -1.38854086e-01, -1.20149292e-01],\n        [ 1.22275777e-01, -1.73236951e-01,  9.68281999e-02, ...,\n         -2.26899497e-02, -1.25950977e-01, -9.36178640e-02],\n        ...,\n        [ 4.18098420e-02, -3.55508253e-02,  1.84215978e-02, ...,\n         -4.93346080e-02, -2.23936290e-02,  3.14317876e-03],\n        [ 4.03414182e-02, -3.67051996e-02,  2.13209521e-02, ...,\n         -5.10725416e-02, -2.21108254e-02,  2.16110423e-03],\n        [ 3.85837369e-02, -3.76900807e-02,  2.40941085e-02, ...,\n         -5.20489626e-02, -2.09680274e-02,  8.14856670e-04]],\n\n       [[ 1.15230605e-01, -1.75690398e-01,  1.07311942e-01, ...,\n          3.92840579e-02, -1.98206678e-01, -1.87087640e-01],\n        [ 1.03689559e-01, -1.86054900e-01,  9.02700722e-02, ...,\n         -6.16995851e-03, -1.70110524e-01, -1.53992429e-01],\n        [ 8.87768641e-02, -1.62051886e-01,  6.71022907e-02, ...,\n         -2.61734538e-02, -1.37159258e-01, -1.06638044e-01],\n        ...,\n        [ 3.81302312e-02, -4.04567309e-02,  3.02057192e-02, ...,\n         -5.30173890e-02, -2.13274155e-02, -1.20547789e-04],\n        [ 3.70287150e-02, -4.03600968e-02,  3.18230055e-02, ...,\n         -5.35710603e-02, -2.00227387e-02, -1.40454492e-03],\n        [ 3.59345488e-02, -3.24431323e-02,  2.78227087e-02, ...,\n         -5.18145896e-02, -1.55981192e-02, -1.40385702e-03]]],\n      dtype=float32)>, <tf.Tensor: shape=(4, 32), dtype=float32, numpy=\narray([[ 0.03852423, -0.03977396,  0.03097809,  0.0268062 ,  0.01037214,\n        -0.00867887, -0.01408828,  0.01632745, -0.00644519, -0.0090787 ,\n         0.00065708,  0.02907316,  0.01132707,  0.00690569,  0.0075836 ,\n        -0.00620464,  0.01836493, -0.00595947, -0.01006926,  0.00744702,\n         0.01262353, -0.01348966, -0.02649496,  0.00319091, -0.03356378,\n         0.02790574, -0.00540946, -0.01241644, -0.01235088, -0.05726673,\n        -0.02042588, -0.00907867],\n       [ 0.03329325, -0.02526998,  0.0262472 ,  0.02639652,  0.01272806,\n        -0.00444763, -0.01951241,  0.01562917, -0.0042487 , -0.01442303,\n        -0.01498307,  0.01780954,  0.00654217,  0.00390607,  0.00348802,\n        -0.01141442,  0.01203612, -0.00538247,  0.00283751,  0.00542295,\n         0.01461416, -0.01393773, -0.01748189,  0.00128355, -0.01920929,\n         0.02943363,  0.00062463, -0.00626285, -0.00749051, -0.05714094,\n        -0.00829854, -0.01365021],\n       [ 0.03858374, -0.03769008,  0.02409411,  0.03081683,  0.00967373,\n        -0.00524354, -0.01436108,  0.0161583 ,  0.00072952, -0.01031537,\n        -0.00780087,  0.02914526,  0.01793195,  0.00688009,  0.00847983,\n        -0.00488962,  0.01849879, -0.00791148, -0.00706185,  0.00224029,\n         0.02184933, -0.00480083, -0.02267156,  0.00782553, -0.02556941,\n         0.02436299, -0.00846352, -0.00661033, -0.00989436, -0.05204896,\n        -0.02096803,  0.00081486],\n       [ 0.03593455, -0.03244313,  0.02782271,  0.02883495,  0.00916785,\n        -0.00239844, -0.01612013,  0.01375926, -0.00122243, -0.01009652,\n        -0.00893536,  0.0221624 ,  0.01481628,  0.00290463,  0.00729949,\n        -0.00913301,  0.01085579, -0.00800052, -0.00454149,  0.00614815,\n         0.02093081, -0.01293947, -0.01878826,  0.00759557, -0.01950686,\n         0.02470042, -0.00498887, -0.00163844, -0.00823578, -0.05181459,\n        -0.01559812, -0.00140386]], dtype=float32)>, <tf.Tensor: shape=(4, 32), dtype=float32, numpy=\narray([[ 0.07764275, -0.07918809,  0.06182315,  0.0545914 ,  0.02115402,\n        -0.01744389, -0.02847142,  0.03231769, -0.01302093, -0.0186513 ,\n         0.00132879,  0.0576674 ,  0.02288856,  0.01383588,  0.01504594,\n        -0.01243544,  0.03642717, -0.01196066, -0.02010663,  0.01497516,\n         0.0249765 , -0.02727969, -0.05346761,  0.00637565, -0.06716283,\n         0.05552963, -0.01071995, -0.02456318, -0.02505902, -0.11589548,\n        -0.04110903, -0.01794573],\n       [ 0.06775688, -0.04964817,  0.05266821,  0.05340831,  0.02619078,\n        -0.0088017 , -0.03923852,  0.03130937, -0.00863604, -0.02933199,\n        -0.03016664,  0.03586756,  0.01309161,  0.00800381,  0.0069807 ,\n        -0.02320504,  0.02405691, -0.01087649,  0.00571634,  0.01105121,\n         0.02907229, -0.02784225, -0.0350995 ,  0.00259973, -0.03880903,\n         0.05872467,  0.00126417, -0.01251615, -0.0151718 , -0.11621708,\n        -0.01672759, -0.02763239],\n       [ 0.07770516, -0.07493159,  0.04803042,  0.06274088,  0.01966042,\n        -0.0105205 , -0.02905336,  0.03199611,  0.00147151, -0.02121487,\n        -0.01573116,  0.0577781 ,  0.03618854,  0.01379687,  0.01682607,\n        -0.00978594,  0.03662731, -0.01588978, -0.01407975,  0.00450955,\n         0.043278  , -0.00972851, -0.04582668,  0.01566267, -0.05107699,\n         0.04840743, -0.01679308, -0.01308776, -0.02011619, -0.10533359,\n        -0.04216123,  0.00160789],\n       [ 0.0731519 , -0.06363121,  0.05587643,  0.05833511,  0.01888536,\n        -0.00474697, -0.03250734,  0.02757991, -0.00248724, -0.02053066,\n        -0.01800266,  0.04472192,  0.02965799,  0.00595296,  0.01459409,\n        -0.01856869,  0.02163313, -0.01621092, -0.00913926,  0.0125271 ,\n         0.04164441, -0.02582221, -0.03770374,  0.01536186, -0.0393817 ,\n         0.04907424, -0.01009305, -0.00327387, -0.01667469, -0.10524912,\n        -0.03148787, -0.00283472]], dtype=float32)>]\n\nCall arguments received by layer 'rnn_decoder_1' (type RNNDecoder):\n  • encoded_images=tf.Tensor(shape=(4, 64), dtype=float32)\n  • captions=tf.Tensor(shape=(4, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     15\u001b[0m rnn_decoder \u001b[38;5;241m=\u001b[39m RNNDecoder(vocab_size, hidden_size, window_size)\n\u001b[0;32m---> 16\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SOLUTION_SHAPE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect output shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/DL/homework-5p-image-captioning-nsahay2004/code/decoder.py:52\u001b[0m, in \u001b[0;36mRNNDecoder.call\u001b[0;34m(self, encoded_images, captions)\u001b[0m\n\u001b[1;32m     50\u001b[0m decoded_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(embedded_captions, (embedded_images,tf\u001b[38;5;241m.\u001b[39mzeros_like(embedded_images)))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#print(decoded_images.shape)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_dense1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(d1)\n\u001b[1;32m     54\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(r2)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'rnn_decoder_1' (type RNNDecoder).\n\nLayer \"dense_6\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(4, 16, 32), dtype=float32, numpy=\narray([[[ 1.45733625e-01, -1.35873660e-01,  1.47979915e-01, ...,\n          3.55866104e-02, -1.86398923e-01, -2.29234964e-01],\n        [ 1.20293491e-01, -1.90315306e-01,  1.29939348e-01, ...,\n         -2.82574585e-03, -1.61929637e-01, -2.14414209e-01],\n        [ 1.00918509e-01, -1.69977397e-01,  1.04164697e-01, ...,\n         -2.50892974e-02, -1.46456361e-01, -1.70868263e-01],\n        ...,\n        [ 4.12754640e-02, -4.02896143e-02,  2.84471344e-02, ...,\n         -5.68455569e-02, -2.42954865e-02, -9.55829024e-03],\n        [ 3.98230366e-02, -4.01531495e-02,  2.96767913e-02, ...,\n         -5.71684316e-02, -2.24347804e-02, -9.09954589e-03],\n        [ 3.85242254e-02, -3.97739597e-02,  3.09780911e-02, ...,\n         -5.72667308e-02, -2.04258822e-02, -9.07866657e-03]],\n\n       [[ 1.01260148e-01, -1.47003919e-01,  8.32417831e-02, ...,\n          2.91540772e-02, -1.77253261e-01, -1.49628803e-01],\n        [ 9.48951766e-02, -1.65624052e-01,  5.37594520e-02, ...,\n         -1.18612265e-02, -1.25592828e-01, -1.81260929e-01],\n        [ 7.56906047e-02, -1.37855321e-01,  3.71033140e-02, ...,\n         -3.39518823e-02, -1.01178534e-01, -1.44572258e-01],\n        ...,\n        [ 3.33542340e-02, -4.23070975e-02,  3.52598056e-02, ...,\n         -6.15393706e-02, -1.57366358e-02, -1.84930544e-02],\n        [ 3.29130106e-02, -3.27946916e-02,  3.05698775e-02, ...,\n         -5.87866157e-02, -1.07600242e-02, -1.56205604e-02],\n        [ 3.32932547e-02, -2.52699815e-02,  2.62472034e-02, ...,\n         -5.71409427e-02, -8.29853769e-03, -1.36502124e-02]],\n\n       [[ 1.58701032e-01, -9.26301032e-02,  1.81446746e-01, ...,\n          2.02374905e-02, -1.28130287e-01, -1.02187917e-01],\n        [ 1.41461164e-01, -1.88737422e-01,  1.29423350e-01, ...,\n         -9.28472541e-03, -1.38854086e-01, -1.20149292e-01],\n        [ 1.22275777e-01, -1.73236951e-01,  9.68281999e-02, ...,\n         -2.26899497e-02, -1.25950977e-01, -9.36178640e-02],\n        ...,\n        [ 4.18098420e-02, -3.55508253e-02,  1.84215978e-02, ...,\n         -4.93346080e-02, -2.23936290e-02,  3.14317876e-03],\n        [ 4.03414182e-02, -3.67051996e-02,  2.13209521e-02, ...,\n         -5.10725416e-02, -2.21108254e-02,  2.16110423e-03],\n        [ 3.85837369e-02, -3.76900807e-02,  2.40941085e-02, ...,\n         -5.20489626e-02, -2.09680274e-02,  8.14856670e-04]],\n\n       [[ 1.15230605e-01, -1.75690398e-01,  1.07311942e-01, ...,\n          3.92840579e-02, -1.98206678e-01, -1.87087640e-01],\n        [ 1.03689559e-01, -1.86054900e-01,  9.02700722e-02, ...,\n         -6.16995851e-03, -1.70110524e-01, -1.53992429e-01],\n        [ 8.87768641e-02, -1.62051886e-01,  6.71022907e-02, ...,\n         -2.61734538e-02, -1.37159258e-01, -1.06638044e-01],\n        ...,\n        [ 3.81302312e-02, -4.04567309e-02,  3.02057192e-02, ...,\n         -5.30173890e-02, -2.13274155e-02, -1.20547789e-04],\n        [ 3.70287150e-02, -4.03600968e-02,  3.18230055e-02, ...,\n         -5.35710603e-02, -2.00227387e-02, -1.40454492e-03],\n        [ 3.59345488e-02, -3.24431323e-02,  2.78227087e-02, ...,\n         -5.18145896e-02, -1.55981192e-02, -1.40385702e-03]]],\n      dtype=float32)>, <tf.Tensor: shape=(4, 32), dtype=float32, numpy=\narray([[ 0.03852423, -0.03977396,  0.03097809,  0.0268062 ,  0.01037214,\n        -0.00867887, -0.01408828,  0.01632745, -0.00644519, -0.0090787 ,\n         0.00065708,  0.02907316,  0.01132707,  0.00690569,  0.0075836 ,\n        -0.00620464,  0.01836493, -0.00595947, -0.01006926,  0.00744702,\n         0.01262353, -0.01348966, -0.02649496,  0.00319091, -0.03356378,\n         0.02790574, -0.00540946, -0.01241644, -0.01235088, -0.05726673,\n        -0.02042588, -0.00907867],\n       [ 0.03329325, -0.02526998,  0.0262472 ,  0.02639652,  0.01272806,\n        -0.00444763, -0.01951241,  0.01562917, -0.0042487 , -0.01442303,\n        -0.01498307,  0.01780954,  0.00654217,  0.00390607,  0.00348802,\n        -0.01141442,  0.01203612, -0.00538247,  0.00283751,  0.00542295,\n         0.01461416, -0.01393773, -0.01748189,  0.00128355, -0.01920929,\n         0.02943363,  0.00062463, -0.00626285, -0.00749051, -0.05714094,\n        -0.00829854, -0.01365021],\n       [ 0.03858374, -0.03769008,  0.02409411,  0.03081683,  0.00967373,\n        -0.00524354, -0.01436108,  0.0161583 ,  0.00072952, -0.01031537,\n        -0.00780087,  0.02914526,  0.01793195,  0.00688009,  0.00847983,\n        -0.00488962,  0.01849879, -0.00791148, -0.00706185,  0.00224029,\n         0.02184933, -0.00480083, -0.02267156,  0.00782553, -0.02556941,\n         0.02436299, -0.00846352, -0.00661033, -0.00989436, -0.05204896,\n        -0.02096803,  0.00081486],\n       [ 0.03593455, -0.03244313,  0.02782271,  0.02883495,  0.00916785,\n        -0.00239844, -0.01612013,  0.01375926, -0.00122243, -0.01009652,\n        -0.00893536,  0.0221624 ,  0.01481628,  0.00290463,  0.00729949,\n        -0.00913301,  0.01085579, -0.00800052, -0.00454149,  0.00614815,\n         0.02093081, -0.01293947, -0.01878826,  0.00759557, -0.01950686,\n         0.02470042, -0.00498887, -0.00163844, -0.00823578, -0.05181459,\n        -0.01559812, -0.00140386]], dtype=float32)>, <tf.Tensor: shape=(4, 32), dtype=float32, numpy=\narray([[ 0.07764275, -0.07918809,  0.06182315,  0.0545914 ,  0.02115402,\n        -0.01744389, -0.02847142,  0.03231769, -0.01302093, -0.0186513 ,\n         0.00132879,  0.0576674 ,  0.02288856,  0.01383588,  0.01504594,\n        -0.01243544,  0.03642717, -0.01196066, -0.02010663,  0.01497516,\n         0.0249765 , -0.02727969, -0.05346761,  0.00637565, -0.06716283,\n         0.05552963, -0.01071995, -0.02456318, -0.02505902, -0.11589548,\n        -0.04110903, -0.01794573],\n       [ 0.06775688, -0.04964817,  0.05266821,  0.05340831,  0.02619078,\n        -0.0088017 , -0.03923852,  0.03130937, -0.00863604, -0.02933199,\n        -0.03016664,  0.03586756,  0.01309161,  0.00800381,  0.0069807 ,\n        -0.02320504,  0.02405691, -0.01087649,  0.00571634,  0.01105121,\n         0.02907229, -0.02784225, -0.0350995 ,  0.00259973, -0.03880903,\n         0.05872467,  0.00126417, -0.01251615, -0.0151718 , -0.11621708,\n        -0.01672759, -0.02763239],\n       [ 0.07770516, -0.07493159,  0.04803042,  0.06274088,  0.01966042,\n        -0.0105205 , -0.02905336,  0.03199611,  0.00147151, -0.02121487,\n        -0.01573116,  0.0577781 ,  0.03618854,  0.01379687,  0.01682607,\n        -0.00978594,  0.03662731, -0.01588978, -0.01407975,  0.00450955,\n         0.043278  , -0.00972851, -0.04582668,  0.01566267, -0.05107699,\n         0.04840743, -0.01679308, -0.01308776, -0.02011619, -0.10533359,\n        -0.04216123,  0.00160789],\n       [ 0.0731519 , -0.06363121,  0.05587643,  0.05833511,  0.01888536,\n        -0.00474697, -0.03250734,  0.02757991, -0.00248724, -0.02053066,\n        -0.01800266,  0.04472192,  0.02965799,  0.00595296,  0.01459409,\n        -0.01856869,  0.02163313, -0.01621092, -0.00913926,  0.0125271 ,\n         0.04164441, -0.02582221, -0.03770374,  0.01536186, -0.0393817 ,\n         0.04907424, -0.01009305, -0.00327387, -0.01667469, -0.10524912,\n        -0.03148787, -0.00283472]], dtype=float32)>]\n\nCall arguments received by layer 'rnn_decoder_1' (type RNNDecoder):\n  • encoded_images=tf.Tensor(shape=(4, 64), dtype=float32)\n  • captions=tf.Tensor(shape=(4, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Test RNN Decoder\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_size = 4\n",
    "window_size = 16\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "SOLUTION_SHAPE = (input_size, window_size, vocab_size)\n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "rnn_decoder = RNNDecoder(vocab_size, hidden_size, window_size)\n",
    "out = rnn_decoder(\n",
    "    tf.random.uniform([input_size, 64], minval=0, maxval=vocab_size),\n",
    "    tf.random.uniform([input_size, window_size], maxval=vocab_size)\n",
    ")\n",
    "epsilon = 1e-5\n",
    "assert out.shape == SOLUTION_SHAPE, \"Incorrect output shape\"\n",
    "assert not (tf.reduce_sum(out) > input_size * window_size - epsilon and tf.reduce_sum(out) < input_size * window_size + epsilon), \"Return logits, not probabilities\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test Transformer Decoder\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_size = 4\n",
    "window_size = 16\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "SOLUTION_SHAPE = (input_size, window_size, vocab_size)\n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "transformer_decoder = TransformerDecoder(vocab_size, hidden_size, window_size)\n",
    "out = transformer_decoder(\n",
    "    tf.random.uniform([input_size, 64], minval=0, maxval=vocab_size),\n",
    "    tf.random.uniform([input_size, window_size], maxval=vocab_size)\n",
    ")\n",
    "epsilon = 1e-5\n",
    "assert out.shape == SOLUTION_SHAPE, \"Incorrect output shape\"\n",
    "assert not (tf.reduce_sum(out) > input_size * window_size - epsilon and tf.reduce_sum(out) < input_size * window_size + epsilon), \"Return logits, not probabilities\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test AttentionHead call function\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [[1.1887338,  0.92231,    1.1832824,  1.4413241,  0.9284028,  1.2374643,\n",
    "   1.2092555,  1.6531762, ],\n",
    "  [1.1876637,  0.920028,   1.1839285,  1.4362004,  0.92912036, 1.2364106,\n",
    "   1.208142,   1.6493324, ],\n",
    "  [1.1947478,  0.92511594, 1.18963,   1.4394116,  0.9363934,  1.2449214,\n",
    "   1.2101097,  1.6523575, ],\n",
    "  [1.177351,   0.9136951,  1.1745526,  1.4348177,  0.91724336, 1.2238563,\n",
    "   1.2058568,  1.6473322, ]],\n",
    "\n",
    " [[1.171719,   0.91546506, 1.2353648,  1.2881929,  0.955095,   1.2792217,\n",
    "   1.3040287,  1.6174344, ],\n",
    "  [1.1937302,  0.9304202,  1.2462558,  1.3073134,  0.9750139,  1.3008424,\n",
    "   1.2973801,  1.6244173, ],\n",
    "  [1.1734747,  0.9167778,  1.2366297,  1.2896433,  0.9566818,  1.281148,\n",
    "   1.304501,   1.618589,  ],\n",
    "  [1.204712,   0.9370769,  1.2490294,  1.3173547,  0.9849655,  1.3102754,\n",
    "   1.2873328,  1.6238908, ]]])\n",
    "\n",
    "def create_deterministic_attention_head(input_size, output_size, is_self_attention):\n",
    "    head = AttentionHead(input_size, output_size, is_self_attention)\n",
    "\n",
    "    head.K = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "    head.V = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "    head.Q = tf.random.uniform([input_size, output_size]) # This is not correct. This is for testing purposes only\n",
    "\n",
    "    return head\n",
    "\n",
    "input_size = 4\n",
    "batch_size = 2\n",
    "window_size_keys = 3\n",
    "window_size_values = 3\n",
    "window_size_queries = 4\n",
    "\n",
    "head = create_deterministic_attention_head(4, 8, False)\n",
    "\n",
    "out = head.call(\n",
    "    tf.random.uniform([batch_size, window_size_keys, input_size], dtype=np.float32),\n",
    "    tf.random.uniform([batch_size, window_size_values, input_size], dtype=np.float32),\n",
    "    tf.random.uniform([batch_size, window_size_queries, input_size], dtype=np.float32)\n",
    ").numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test TransformerBlock\n",
    "# DO NOT CHANGE\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [[0.         ,0.6974105  ,0.98577017 ,0.        ],\n",
    "  [0.         ,0.31697747 ,1.4552947  ,0.        ],\n",
    "  [0.         ,0.         ,1.6302229  ,0.        ],\n",
    "  [0.8908619  ,0.761421   ,0.         ,0.        ],\n",
    "  [0.         ,1.093846   ,0.         ,0.85964626],\n",
    "  [0.         ,0.         ,1.1071919  ,0.84442014],\n",
    "  [0.         ,0.7972666  ,0.         ,1.1266519 ],\n",
    "  [0.         ,0.         ,1.6696594  ,0.        ]],\n",
    "\n",
    " [[0.         ,0.         ,1.6952605  ,0.        ],\n",
    "  [0.         ,1.040991   ,0.9518903  ,0.        ],\n",
    "  [0.         ,0.9950613  ,0.19130549 ,0.47112876],\n",
    "  [0.         ,1.2255263  ,0.72682804 ,0.        ],\n",
    "  [0.59422725 ,0.         ,1.3293806  ,0.        ],\n",
    "  [1.56447    ,0.         ,0.         ,0.01488148],\n",
    "  [0.         ,0.6034657  ,0.         ,1.1571136 ],\n",
    "  [0.         ,0.18686305 ,0.29973274 ,1.1265295 ]]])\n",
    "\n",
    "batch_size = 2\n",
    "input_seq_length = 8\n",
    "embedding_size = 4\n",
    "context_seq_length = 6\n",
    "multiheadedattention = False\n",
    "\n",
    "transformer_block = TransformerBlock(embedding_size, multiheadedattention)\n",
    "transformer_block.self_atten = create_deterministic_attention_head(embedding_size, embedding_size, True)  # This is not correct. This is for testing purposes only\n",
    "transformer_block.self_context_atten = create_deterministic_attention_head(embedding_size, embedding_size, True)  # This is not correct. This is for testing purposes only\n",
    "transformer_block.ff_layer = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.constant()) #  # This is not correct. This is for testing purposes only\n",
    "\n",
    "out = transformer_block(\n",
    "    tf.random.uniform([batch_size, input_seq_length, embedding_size]),\n",
    "    tf.random.uniform([batch_size, context_seq_length, embedding_size])\n",
    ").numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "assert not (out < 0).any(), \"Incorrect output activation\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test Positional Encoding\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "SOLUTION = np.array([\n",
    " [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
    "   1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
    " [ 8.4147096e-01,  9.9833414e-02,  9.9998331e-03,  9.9999981e-04,\n",
    "   5.4030228e-01,  9.9500418e-01,  9.9994999e-01,  9.9999952e-01],\n",
    " [ 9.0929741e-01,  1.9866933e-01,  1.9998666e-02,  1.9999987e-03,\n",
    "  -4.1614684e-01,  9.8006660e-01,  9.9980003e-01,  9.9999797e-01],\n",
    " [ 1.4112000e-01,  2.9552022e-01,  2.9995501e-02,  2.9999956e-03,\n",
    "  -9.8999250e-01,  9.5533651e-01,  9.9955004e-01,  9.9999553e-01]])\n",
    "\n",
    "input_size = 4\n",
    "window_size = 4\n",
    "embed_size = 8\n",
    "vocab_size = 2\n",
    "\n",
    "dummy_layer = tf.keras.layers.Dense(embed_size, kernel_initializer=tf.keras.initializers.constant())\n",
    "\n",
    "positional_encoding = PositionalEncoding(vocab_size, embed_size, window_size)\n",
    "positional_encoding.embedding = dummy_layer  # This is not correct. This is for testing purposes only\n",
    "\n",
    "out = positional_encoding.call(tf.random.uniform([input_size, window_size])).numpy()\n",
    "\n",
    "assert out.shape == SOLUTION.shape, \"Incorrect output shape\"\n",
    "try: assert np.allclose(out, SOLUTION, rtol=0.001), \"Incorrect output values\"\n",
    "except AssertionError:\n",
    "    print(\"Output:\")\n",
    "    print(out)\n",
    "    print(\"Solution:\")\n",
    "    print(SOLUTION)\n",
    "    assert False, \"Incorrect output values\"\n",
    "print(\"Tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
